{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_set_download.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santhoshBjeeffy/Dog_Breed_classifier/blob/master/Data_set_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEfm4dStKznB",
        "colab_type": "text"
      },
      "source": [
        "#Dataset Download\n",
        "\n",
        "For this model we will be creating the dataset by considering below six varieties of dog breeds.\n",
        "\n",
        "1.pug \n",
        "\n",
        "2.Bull dog \n",
        "\n",
        "3.Labrador Reterviver \n",
        "\n",
        "4.Beale \n",
        "\n",
        "5.pomeranian \n",
        "\n",
        "6.German shephard\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpgGcGy8KmnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ni1M2ULHZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=[\"pug\",\"bulldog\",\"labradorreterviver\",\"beagle\",\"pomeranian\",\"germanshephard\"]\n",
        "for folder in classes:\n",
        "  folder=folder\n",
        "  path=Path('/content/drive/My Drive/Colab Notebooks/Fast.ai_assignments/move')\n",
        "  dest=path/folder\n",
        "  file= folder+'.txt'\n",
        "  download_images(path/file, dest, max_pics=200)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rMbv01qL78D",
        "colab_type": "text"
      },
      "source": [
        "Taken from Jeremy Howard's Notebook:\n",
        "\n",
        "Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset. First, go to Google Images and search for the images you want per class. Once you're on the results page, press CtrlShiftJ in Windows/Linux and CmdOptJ in Mac, and a small window the javascript 'Console' will appear. That is where you will paste the JavaScript commands.\n",
        "\n",
        "You will need to get the urls of each of the images. Before running the following commands, you may want to disable ad blocking extensions (uBlock, AdBlockPlus etc.) in Chrome. Otherwise the window.open() command doesn't work. Then you can run the following commands:\n",
        "\n",
        "\n",
        "urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\n",
        "window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n'))); *italicized text* italicized text\n",
        "\n",
        "\n",
        "This will generate a CSV file that contains the direct links to each image that show up on the Google image search. Make sure you name the CSV file exactly corresponding to how each character's name is spelt in the classes list and save them all in the directory defined by path above.\n",
        "\n",
        "For completeness, they are included in this repo and in the same directory as this notebook. We will now download the images specified by the URLs defined in each CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvjEgd62LkK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\n",
        "window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWxv0tL-MejX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in classes:\n",
        "    dest = path/c\n",
        "    s = c + '.csv'\n",
        "    print('Dest: {} - File: {}'.format(dest, s))\n",
        "    download_images(path/s, dest, max_pics=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C1e_QbbMkNN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Also, let's go through the images and delete any we can't open\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0X1WSHwMlQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in classes:\n",
        "    verify_images(path/c, delete=True, max_size=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIZ5xyGxMywH",
        "colab_type": "text"
      },
      "source": [
        " Now let's zip it up so we can proceed to the next part and start training. Training will be done on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihy5QGR4Mrw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('tng_dataset', 'zip', path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}